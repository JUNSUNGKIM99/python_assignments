{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch1, Training loss2.273669719696045\n",
      "Epoch10, Training loss0.8017953634262085\n",
      "Epoch20, Training loss0.39260053634643555\n",
      "Epoch30, Training loss0.276013046503067\n",
      "Epoch40, Training loss0.14580915868282318\n",
      "Epoch50, Training loss0.46126383543014526\n",
      "Epoch60, Training loss0.36156022548675537\n",
      "Epoch70, Training loss0.07252158224582672\n",
      "Epoch80, Training loss0.2878243327140808\n",
      "Epoch90, Training loss0.14413675665855408\n",
      "Epoch100, Training loss0.14416943490505219\n",
      "Epoch110, Training loss0.5065944790840149\n",
      "Epoch120, Training loss8.552281360607594e-05\n",
      "Epoch130, Training loss0.14483048021793365\n",
      "Epoch140, Training loss0.21641796827316284\n",
      "Epoch150, Training loss0.0719677284359932\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "########################################## Lenet-5 Network\n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu5(out)\n",
    "        return out\n",
    "###########################################\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 64\n",
    "    mnist_train = mnist.MNIST('./train', train=True, download=True, transform=ToTensor())\n",
    "    mnist_test = mnist.MNIST('./test', train=False, download=True, transform=ToTensor())\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)    \n",
    "    net = Net()\n",
    "    #The cost function we used for logistic regression\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    n_epochs = 150\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "        train_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(imgs)\n",
    "            train_loss = loss_fn(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\"Epoch{}, Training loss{}\".format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Section \n",
    "from sys\n",
    "from PIL import Image\n",
    "mnist_sample = mnist.MNIST('./sample',train=False,download=True, transform=None)\n",
    "for j in range(100):\n",
    "    for i in range(10):\n",
    "        if mnist_sample[j][1] == 0:\n",
    "            mnist_sample[j][0].save('zero.png')\n",
    "        elif mnist_sample[j][1] == 1:\n",
    "            mnist_sample[j][0].save('one.png')\n",
    "        elif mnist_sample[j][1] == 2:\n",
    "            mnist_sample[j][0].save('two.png')\n",
    "        elif mnist_sample[j][1] == 3:\n",
    "            mnist_sample[j][0].save('three.png')\n",
    "        elif mnist_sample[j][1] == 4:\n",
    "            mnist_sample[j][0].save('four.png')\n",
    "        elif mnist_sample[j][1] == 5:\n",
    "            mnist_sample[j][0].save('five.png')\n",
    "        elif mnist_sample[j][1] == 6:\n",
    "            mnist_sample[j][0].save('six.png')\n",
    "        elif mnist_sample[j][1] == 7:\n",
    "            mnist_sample[j][0].save('seven.png')\n",
    "        elif mnist_sample[j][1] == 8:\n",
    "            mnist_sample[j][0].save('eight.png')\n",
    "        elif mnist_sample[j][1] == 9:\n",
    "            mnist_sample[j][0].save('nine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Usage>: Prediction value is not coming ex)'one.png' \nAssume : 4\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv) != 1:\n",
    "        print(\n",
    "            \"<Usage>: Prediction value is not coming ex)'one.png' \"\n",
    "        )  # program이나py파일이 하나라도 안들어왔을 경우 exception 처리\n",
    "        exit(1)\n",
    "image_ = Image.open('four.png')\n",
    "image = torch.zeros(16,1,28,28)\n",
    "transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(), # image to Tensor\n",
    "                             ])\n",
    "image = image + transform(image_)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "# forward propagation\n",
    "model_output = net(image)\n",
    "print(f\"Assume : {model_output.argmax(dim=1)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}